{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e81664cf",
   "metadata": {},
   "source": [
    "### connect s3 using boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8c21998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05deb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connect to s3 object storage\n",
    "s3 = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f46ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a bucket called 'new-bucket-bxiao5050'\n",
    "location = {'LocationConstraint': 'eu-central-1'}\n",
    "new_bucket = s3.create_bucket(Bucket = 'new-bucket-bxiao5050', CreateBucketConfiguration=location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2eb84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bxiaobxiao.bucket\n",
      "new-bucket-bxiao5050\n"
     ]
    }
   ],
   "source": [
    "#view all buckets in s3\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bf3a25",
   "metadata": {},
   "source": [
    "#### select a bucket, and upload, download and delete objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "667cd8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select bucket of 'bxiaobxiao.bucket'\n",
    "bucket = s3.Bucket('bxiaobxiao.bucket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1825a515",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload a file\n",
    "local_file_path = '2022-04-25_BINS_XETR1415.csv'\n",
    "key_object = 'added/a/new/object/test_data.csv'\n",
    "\n",
    "bucket.upload_file(local_file_path, key_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c853696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='bxiaobxiao.bucket', key='added/a/new/object/data.csv')\n",
      "s3.ObjectSummary(bucket_name='bxiaobxiao.bucket', key='added/a/new/object/test_data.csv')\n"
     ]
    }
   ],
   "source": [
    "#show all objects from 'bxiaobxiao.bucket'\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b28a59",
   "metadata": {},
   "source": [
    "##### convert an object to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c20e498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#get the content of this object, the content is in the string format\n",
    "csv_obj = bucket.Object(key = 'added/a/new/object/data.csv').get().get('Body').read().decode('utf-8')\n",
    "print(type(csv_obj))\n",
    "csv_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acc90a3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Mnemonic</th>\n",
       "      <th>SecurityDesc</th>\n",
       "      <th>SecurityType</th>\n",
       "      <th>Currency</th>\n",
       "      <th>SecurityID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>StartPrice</th>\n",
       "      <th>MaxPrice</th>\n",
       "      <th>MinPrice</th>\n",
       "      <th>EndPrice</th>\n",
       "      <th>TradedVolume</th>\n",
       "      <th>NumberOfTrades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT0000A0E9W5</td>\n",
       "      <td>SANT</td>\n",
       "      <td>S+T AG O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504159</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>08:00</td>\n",
       "      <td>15.14</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.11</td>\n",
       "      <td>15.25</td>\n",
       "      <td>14239</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE000A0DJ6J9</td>\n",
       "      <td>S92</td>\n",
       "      <td>SMA SOLAR TECHNOL.AG</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504287</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>08:00</td>\n",
       "      <td>32.80</td>\n",
       "      <td>32.80</td>\n",
       "      <td>32.80</td>\n",
       "      <td>32.80</td>\n",
       "      <td>357</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DE000A0D6554</td>\n",
       "      <td>NDX1</td>\n",
       "      <td>NORDEX SE O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504290</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>08:00</td>\n",
       "      <td>13.97</td>\n",
       "      <td>14.10</td>\n",
       "      <td>13.96</td>\n",
       "      <td>14.09</td>\n",
       "      <td>18908</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE000A0D9PT0</td>\n",
       "      <td>MTX</td>\n",
       "      <td>MTU AERO ENGINES NA O.N.</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504297</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>08:00</td>\n",
       "      <td>198.60</td>\n",
       "      <td>199.15</td>\n",
       "      <td>198.10</td>\n",
       "      <td>198.65</td>\n",
       "      <td>2216</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DE000A0HN5C6</td>\n",
       "      <td>DWNI</td>\n",
       "      <td>DEUTSCHE WOHNEN SE INH</td>\n",
       "      <td>Common stock</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2504314</td>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>08:00</td>\n",
       "      <td>35.49</td>\n",
       "      <td>35.49</td>\n",
       "      <td>35.38</td>\n",
       "      <td>35.43</td>\n",
       "      <td>469</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ISIN Mnemonic              SecurityDesc  SecurityType Currency  \\\n",
       "0  AT0000A0E9W5     SANT               S+T AG O.N.  Common stock      EUR   \n",
       "1  DE000A0DJ6J9      S92      SMA SOLAR TECHNOL.AG  Common stock      EUR   \n",
       "2  DE000A0D6554     NDX1            NORDEX SE O.N.  Common stock      EUR   \n",
       "3  DE000A0D9PT0      MTX  MTU AERO ENGINES NA O.N.  Common stock      EUR   \n",
       "4  DE000A0HN5C6     DWNI    DEUTSCHE WOHNEN SE INH  Common stock      EUR   \n",
       "\n",
       "   SecurityID        Date   Time  StartPrice  MaxPrice  MinPrice  EndPrice  \\\n",
       "0     2504159  2022-01-20  08:00       15.14     15.25     15.11     15.25   \n",
       "1     2504287  2022-01-20  08:00       32.80     32.80     32.80     32.80   \n",
       "2     2504290  2022-01-20  08:00       13.97     14.10     13.96     14.09   \n",
       "3     2504297  2022-01-20  08:00      198.60    199.15    198.10    198.65   \n",
       "4     2504314  2022-01-20  08:00       35.49     35.49     35.38     35.43   \n",
       "\n",
       "   TradedVolume  NumberOfTrades  \n",
       "0         14239               9  \n",
       "1           357               1  \n",
       "2         18908              32  \n",
       "3          2216              29  \n",
       "4           469               6  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use package StringIO to convert string to dataframe\n",
    "from io import StringIO\n",
    "data = StringIO(csv_obj)\n",
    "\n",
    "df = pd.read_csv(data, delimiter = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a63e1",
   "metadata": {},
   "source": [
    "#### convert dataframe to parquet and upload to s3 (bucket name: new-bucket-bxiao5050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48211c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "s3.Object(bucket_name='new-bucket-bxiao5050', key='upload/a/file/xxx.parquet')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#need to install pyarrow package, and use io.BytesIO to get a buffer to the parquet content\n",
    "from io import BytesIO\n",
    "\n",
    "out_buffer = BytesIO()\n",
    "df_new = df[['ISIN', 'EndPrice']]\n",
    "df_new.to_parquet(out_buffer, index = False)\n",
    "\n",
    "s3.Bucket('new-bucket-bxiao5050').put_object(Body=out_buffer.getvalue(), Key = 'upload/a/file/xxx.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5b13c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3.ObjectSummary(bucket_name='new-bucket-bxiao5050', key='upload/a/file/xxx.parquet')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list all objects from new-bucket-bxiao5050 bucket\n",
    "[print(obj) for obj in s3.Bucket('new-bucket-bxiao5050').objects.all()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b236d308",
   "metadata": {},
   "source": [
    "#### read the uploaded parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2fd6d86e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Could not open Parquet input source '<Buffer>': Parquet file size is 0 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [41], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m prq_obj \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39mBucket(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnew-bucket-bxiao5050\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mObject(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupload/a/file/xxx.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m BytesIO(prq_obj)\n\u001b[0;32m----> 3\u001b[0m df_prq \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m df_prq\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pandas/io/parquet.py:503\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03mLoad a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;124;03mDataFrame\u001b[39;00m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    501\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pandas/io/parquet.py:251\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m path_or_handle, handles, kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    245\u001b[0m     path,\n\u001b[1;32m    246\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilesystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    248\u001b[0m     mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    249\u001b[0m )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 251\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_pandas(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mto_pandas_kwargs)\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    255\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pyarrow/parquet/core.py:2824\u001b[0m, in \u001b[0;36mread_table\u001b[0;34m(source, columns, use_threads, metadata, schema, use_pandas_metadata, memory_map, read_dictionary, filesystem, filters, buffer_size, partitioning, use_legacy_dataset, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, decryption_properties, thrift_string_size_limit, thrift_container_size_limit)\u001b[0m\n\u001b[1;32m   2817\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2818\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m keyword is no longer supported with the new \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2819\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets-based implementation. Specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2820\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_legacy_dataset=True\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to temporarily recover the old \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2821\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbehaviour.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2822\u001b[0m     )\n\u001b[1;32m   2823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2824\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43m_ParquetDatasetV2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2825\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartitioning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_dictionary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_prefixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_prefixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_int96_timestamp_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_string_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthrift_container_size_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2838\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2839\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m   2840\u001b[0m     \u001b[38;5;66;03m# fall back on ParquetFile for simple cases when pyarrow.dataset\u001b[39;00m\n\u001b[1;32m   2841\u001b[0m     \u001b[38;5;66;03m# module is not available\u001b[39;00m\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pyarrow/parquet/core.py:2412\u001b[0m, in \u001b[0;36m_ParquetDatasetV2.__init__\u001b[0;34m(self, path_or_paths, filesystem, filters, partitioning, read_dictionary, buffer_size, memory_map, ignore_prefixes, pre_buffer, coerce_int96_timestamp_unit, schema, decryption_properties, thrift_string_size_limit, thrift_container_size_limit, **kwargs)\u001b[0m\n\u001b[1;32m   2408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m single_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2409\u001b[0m     fragment \u001b[38;5;241m=\u001b[39m parquet_format\u001b[38;5;241m.\u001b[39mmake_fragment(single_file, filesystem)\n\u001b[1;32m   2411\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39mFileSystemDataset(\n\u001b[0;32m-> 2412\u001b[0m         [fragment], schema\u001b[38;5;241m=\u001b[39mschema \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mfragment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphysical_schema\u001b[49m,\n\u001b[1;32m   2413\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mparquet_format,\n\u001b[1;32m   2414\u001b[0m         filesystem\u001b[38;5;241m=\u001b[39mfragment\u001b[38;5;241m.\u001b[39mfilesystem\n\u001b[1;32m   2415\u001b[0m     )\n\u001b[1;32m   2416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# check partitioning to enable dictionary encoding\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pyarrow/_dataset.pyx:905\u001b[0m, in \u001b[0;36mpyarrow._dataset.Fragment.physical_schema.__get__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/end-to-end-project-PySpark-PKTHgxxZ/lib/python3.11/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Could not open Parquet input source '<Buffer>': Parquet file size is 0 bytes"
     ]
    }
   ],
   "source": [
    "prq_obj = s3.Bucket('new-bucket-bxiao5050').Object(key='upload/a/file/xxx.parquet').get().get('Body').read()\n",
    "data = BytesIO(prq_obj)\n",
    "df_prq = pd.read_parquet(data)\n",
    "df_prq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bf46d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b''"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prq_obj = s3.Bucket('new-bucket-bxiao5050').Object(key='upload/a/file/xxx.parquet').get().get('Body').read()\n",
    "prq_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc86ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
